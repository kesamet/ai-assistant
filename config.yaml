MODEL_LLAMA2CHAT: "./models/llama-2-7b-chat.ggmlv3.q2_K.bin"
MODEL_CODELLAMA: "./models/codellama-7b-instruct.Q2_K.gguf"
MODEL_TYPE: "llama"

MAX_NEW_TOKENS: 512
TEMPERATURE: 0.2
REPETITION_PENALTY: 1.1
CONTEXT_LENGTH: 1024

HOST: "localhost"
PORT_LLAMA2CHAT: 8201
PORT_CODELLAMA: 8202
