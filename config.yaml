DEVICE: cpu

MODELS_DIR: ./models

LLAMA2:
  MODEL_NAME: llama-2-7b-chat
  MODEL_PATH: llama-2-7b-chat.Q4_K_M.gguf

CODELLAMA:
  MODEL_NAME: codellama-7b-instruct
  MODEL_PATH: codellama-7b-instruct.Q2_K.gguf

MISTRAL:
  MODEL_NAME: mistral-7b-instruct-v0.2
  MODEL_PATH: mistral-7b-instruct-v0.2.Q4_K_M.gguf

LLM_CONFIG:
  MAX_NEW_TOKENS: 512
  TEMPERATURE: 0.2
  REPETITION_PENALTY: 1.1
  CONTEXT_LENGTH: 2048

CLIP_MODEL_PATH: llava-7b/mmproj-model-f16.gguf
LLAVA_MODEL_PATH: llava-7b/ggml-model-q4_k.gguf

HOST: localhost
PORT:
  LLAMA2: 8201
  CODELLAMA: 8202
  MISTRAL: 8203
  LLAVA: 8210
